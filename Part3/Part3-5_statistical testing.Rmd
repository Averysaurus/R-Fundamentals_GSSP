---
title: 'R Fundamentals Part3-5: intro to statistical testing'
author: "D-Lab"
date: "March 31, 2019 (updated `r Sys.Date()`)"
output: html_document
---

> DISCLAIMER! If you are interested in any of the tests presented in this lesson, make sure you understand the prerequisite data assumptions for these tests by taking stats classes at UC Berkeley (see the readme file for links), talking to your advisor, and/or speaking with your local statistician. 

# Statistical testing

Now that you have learned to summarize and visualize data, it is time to get familiar with some statistical basics. Remember that **you** must investigate the assumptions of all of these tests, which are not covered here. The purpose of this lesson is to cover how to code some basic statistical tests in R - their assumptions and validity are for your to discuss with your cohort, colleagues, advisor, supervisor, mentor, local statistician, etc. 

## Hypothesis testing

You will frequently encounter hypotheses in the peer-reviewed literature and in the output of test results in R. Hypotheses generally should be based on research questions and expectations about the data. 

**Hypothesis testing** is central to research. How can you tell if the differences you observe are statistically real or not? We answer such questions through hypothesis formulation and significance testing as measured by p-values.  

## The null and alternate hypotheses

The simplest way to think about hypothesis testing is that you have two hypotheses: the null (Ho) and the alternative (Ha). 

The null hypothesis can be thought of as **NO DIFFERENCE / RELATIONSHIP / CORRELATION**  

The alternative hypothesis can be thought of as **SOME SORT OF DIFFERENCE / RELATIONSHIP / CORRELATION**  

## p-value

In this oversimplified example these are your only two options and are tested using a "p-value". A p-value signifies how likely differences are statistically real instead of due to random chance. Or, it specifies the probability of finding a value as or more extreme under the null hypothesis. The most common standard cutoff value is p < 0.05.  

If p > 0.05, you **FAIL TO REJECT THE NULL HYPOTHESIS**! By default we accept the conditions of the null hypothesis - "no difference / relationship / correlation" among the variables being tested. 

If p < 0.05, you **REJECT THE NULL HYPOTHESIS** of "no difference / relationship / correlation" and by default you accept the alternative hypothesis and whatever "difference / relationship / correlation" it specified. This is a **_"statistically significant"_** difference.  

Even though they _look_ similar, we can ask: are there formal statistically significant differences between the means of versicolor and virginica petal lengths? Well, we can test those assumptions with "mean comparison" tests such as t-tests and analysis of variance (ANOVA)!  

# Student's t-test

A t-test formally compares **one or two group means** for statistically significant differences. We can use `t.test` to make an observation of a population based on a sample. We are only examining a handful of petal lengths - if we had ALL petal lengths there would be no need for a statistic - instead, we would only be concerned with what we observe!   

The null hypothesis states that there are no actual mean differences between the two groups. 

# **Challenge 8**

1. What are the assumptions for a t-test?  
2. Fit a t-test for Petal Lengths between iris versicolor and virginica species.  
3. What does this result mean?  

```{r, eval = F}
## YOUR CODE HERE
```


## One-way analysis of variance 

What about if we want to compare more than two groups? Doing multiple pairwise t-tests for *1)* setosa v. versicolor, *2)* setosa v. virginica, and *3)* versicolor v. virginica is not ideal because it becomes more difficult to adjust for the [family wise error rate](https://en.wikipedia.org/wiki/Family-wise_error_rate), or the influence of the other groups/variables that are present but not necessarily being being tested.

When we want to compare more than two group means at once (gdpPercap of the the five continents from `gap`, for example), we can use an analysis of variance (ANOVA). This is called by `aov` in R.

We can then follow `aov` with a "Tukey test of Honest Significant Difference" to find out between exactly which groups the differences (if any) exist. This is called with `TukeyHSD` in R.

Let's try! Note the slightly different syntax - we can now specify only the column headings, and enter the name of our data frame in the `data` argument. Let's call our object `gap_aov`, which is an object we can unpack and look inside:

```{r}
gap_aov <- aov(gdpPercap ~ continent, data = gap)

#Use `summary()` to access the useful information from our `aov1` model:
summary(gap_aov)
```

We receive a highly significant p-value. But how do we know between which continents the differences actually exist? We can follow this up with a TukeyHSD test to see which between-group differences contribute most:

```{r}
TukeyHSD(gap_aov)
```

This allows us to see mean differences bewteen the multiple continents with adjusted p-values. Most adjusted p-values are zero, meaning there is potentially a strong difference in gdpPercap between the paired continents. There appear to be no differences in gdpPercap between Asia and the Americas (p = 0.7767582) and Oceania and Europe (p = 0.1539474) "diff" is the mean difference between the two groups and "lwr" and "upr" are the confidence interval boundaries.  

# **Challenge 9**

1. What are the assumptions for a one-way analysis of variance?  
2. Use the `mtcars` dataset to perform an ANOVA and TukeyHSD test for mpg between the three cyl sizes (4, 6, and 8). 

```{r}
## YOUR CODE HERE
```

## Linear correlation

Linear [correlation](https://en.wikiversity.org/wiki/Correlation) is a useful way to see if two numeric variables are associated. "Pearson's r" is the default coefficient in `cor.test()`. Correlation is a number that ranges between -1 and 1 with -1 indicating a negative correlation and 1 indicating a positive correlation. 

Use `gap` to see if gdpPercap and lifeExp are correlated: 

```{r}
cor.test(gap$gdpPercap, gap$lifeExp)
```

Yes - results indicate a moderate/strong positive correlation (cor = 0.5837062) that is also highly significant (p < 0.00000000000000022).  

> NOTE! Remember that correlation does not necessarily equal causation! 

## Fit a linear regression

Now what? Linear regression is a convenient way to see if one numeric variable can be used to predict another. Do you think Sepal.Width can be used to predict Petal.Length?  

Again, note the altered syntax: `model1 <- lm(Y ~ X, data=data)`

Y is the **DEPENDENT**, target, response, or outcome variable. This is the variable we want to predict.

X is the **INDEPENDENT**, predictor, input, or explanatory variable. 

We can use X (gdpPercap) to predict the outcome of Y (lifeExp) from `gap`

```{r}
gap_lm1 <- lm(lifeExp ~ gdpPercap, data = gap)
summary(gap_lm1)
```

`lm()` output is dense! Check out [the yhat blog for fitting and interpreting linear models](http://blog.yhat.com/posts/r-lm-summary.html). Also be aware that we have not discussed [data assumptions](https://en.wikipedia.org/wiki/Linear_regression#Assumptions) for using `lm` or any of the other tests in this file, or when it is specifically appropriate (or inappropriate) to use them. 

You can also pull items out of return objects using `names()`. To extract the residuals we would use the dollar sign operator `$`. Let's fit a best fit line to a scatterplot. 

```{r, eval=FALSE}
names(gap_lm1)

gap_lm1$coefficients

ggplot(gap, aes(x = gdpPercap, y = lifeExp)) + 
  geom_point() + 
  geom_smooth(method = "lm", col = "red")
```
